{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from deap import creator, tools, base\n",
    "import numpy as np\n",
    "import random\n",
    "from stage import fullPrint, getStage\n",
    "from datetime import datetime, date\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "# import mysqlToolboxÂ \n",
    "# import mariadb\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Warning Statements\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning) \n",
    "\n",
    "## Imports Functions from Toolbox\n",
    "from estimatorToolbox import calculateGroupReturn\n",
    "from estimatorToolbox import evalReturn\n",
    "from estimatorToolbox import generate_random_num_attr\n",
    "from estimatorToolbox import mutate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize Creator & Toolbox\n",
    "# Initialize Deap Creator Objects\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,1,0))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Toolbox\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_bool\", generate_random_num_attr) # Attribute generator \n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, \n",
    "    toolbox.attr_bool, 1) # Structure initializers\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"evaluate\", evalReturn)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", mutate)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize Variables \n",
    "now = datetime.now()\n",
    "\n",
    "#Initilize Backtest Transaction Database\n",
    "transactionTemplate = pd.read_pickle('stockData/industriesData/XLB/DJMining.pkl').drop(['Open','High','Low','Close','Volume','Currency'],axis = 1)\n",
    "transactionTemplate['Dates'] = pd.to_datetime(transactionTemplate.index)\n",
    "transactionTemplate = transactionTemplate[transactionTemplate['Dates'].dt.weekday == 6]\n",
    "transactionTemplate = transactionTemplate.drop('Dates', axis = 1)\n",
    "transactionTemplate = transactionTemplate[~transactionTemplate.index.duplicated()]\n",
    "transactionTemplate.to_pickle(\"transactionTemplate.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get list of returns of tickers\n",
    "industryList = pd.read_pickle(\"stockData/industryList.pkl\")\n",
    "listOfDf = calculateGroupReturn(industryList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize Test/Train Stock Lists and Check test vs train return\n",
    "\n",
    "train, test = train_test_split(industryList, test_size=0.3, shuffle=True)\n",
    "testTrainR = []\n",
    "def calculateTestTrainRatio(train,test):\n",
    "    testTrainRatio = [1,1]\n",
    "    for i in range(2):\n",
    "        if i == 0:\n",
    "            l = test\n",
    "        else:\n",
    "            l = train\n",
    "        index = 0\n",
    "        industries = [x[1] for x in l]\n",
    "        while index != len(l):\n",
    "            if industries[index] not in list(listOfDf.columns):\n",
    "                lindustries = np.delete(industries, index)\n",
    "            else:\n",
    "                index += 1\n",
    "        for index, element in listOfDf[industries].iterrows():\n",
    "            #print(element.to_list())\n",
    "            listOfStockRet = element.to_list()\n",
    "            while 1.0 in listOfStockRet:\n",
    "                listOfStockRet.remove(1.0)\n",
    "            if len(listOfStockRet) != 0:\n",
    "                testTrainRatio[i] = testTrainRatio[i] * np.mean(listOfStockRet)     \n",
    "    testTrainRatio[1] = testTrainRatio[1] / testTrainRatio[0]\n",
    "    testTrainRatio[0] = 1\n",
    "    return testTrainRatio\n",
    "testTrainR = calculateTestTrainRatio(train,test)\n",
    "while(abs(1-testTrainR[1])/np.average(testTrainR)>0.2):\n",
    "    train, test = train_test_split(industryList, test_size=0.3, shuffle=True)\n",
    "    testTrainR = calculateTestTrainRatio(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate (and normalize) returns of each folds \n",
    "trainSet1, trainSet2, trainSet3  = np.array_split(train,3,)\n",
    "trainSets = [trainSet1, trainSet2, trainSet3]\n",
    "trainSetsR = []\n",
    "def trainSetsRatio(ratio):\n",
    "    ratio = [1,1,1,1,1,1]\n",
    "    for i in range(6):\n",
    "        if i < 3:\n",
    "            l = trainSets[i]\n",
    "        else:\n",
    "            l = np.concatenate((trainSets[(i+1)%3],trainSets[(i+2)%3]))\n",
    "        industries = [x[1] for x in l]\n",
    "        index = 0\n",
    "        while index != len(l):\n",
    "            if industries[index] not in list(listOfDf.columns):\n",
    "                industries[index] = np.delete(industries, index)\n",
    "            else:\n",
    "                index += 1\n",
    "        for index, element in listOfDf[industries].iterrows():\n",
    "            #print(element.to_list())\n",
    "            listOfStockRet = element.to_list()\n",
    "            while 1.0 in listOfStockRet:\n",
    "                listOfStockRet.remove(1.0)\n",
    "            if len(listOfStockRet) != 0:\n",
    "                ratio[i] = ratio[i] * np.mean(listOfStockRet)\n",
    "    for i in range(1,6):\n",
    "        ratio[i] = ratio[i] / ratio[0]\n",
    "    ratio[0] = 1.0\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSetsR = trainSetsRatio(trainSetsR)\n",
    "while(np.std(trainSetsR)/np.average(trainSetsR)>0.2):\n",
    "        np.random.shuffle(train)\n",
    "        trainSet1, trainSet2, trainSet3  = np.array_split(train,3)\n",
    "        trainSets = [trainSet1, trainSet2, trainSet3]\n",
    "        trainSetsR = trainSetsRatio(trainSetsR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('testSetPickle/trainSet.pkl', 'wb') as f:\n",
    "    pickle.dump(trainSets, f)\n",
    "with open('testSetPickle/trainSetRatio.pkl', 'wb') as f:\n",
    "    pickle.dump(trainSetsR, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initilize Output File & Write Testsets to the TXT File\n",
    "resultFile = open(\"estimatorData/resultML\"+date.today().strftime('%Y-%m-%d')+\".txt\",\"a\")\n",
    "resultFile.write(\"trainSets \"+str(trainSets)+\"\\n\")\n",
    "resultFile.write(\"test \"+str(test)+\"\\n\")\n",
    "resultFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = toolbox.population(n=10)\n",
    "for ind in pop:\n",
    "    paramStr = ' '.join(map(str, ind[0]))\n",
    "    # cur.execute(\"INSERT INTO Params (param,result) VALUES (?, NULL)\", (paramStr,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the entire population\n",
    "# here\n",
    "pool = Pool()\n",
    "# tempResult = pool.map(toolbox.evaluate, pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitnesses = map(toolbox.evaluate, pop)\n",
    "# print(fitnesses)\n",
    "# here\n",
    "# pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, fit in zip(pop, fitnesses):\n",
    "    ind.fitness.values = fit\n",
    "    if ind.fitness.values[0]<=100:\n",
    "        del ind.fitness.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('stockData/industriesData/XLB/DJAluminum.pkl')\n",
    "fullPrint(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea40916e32696a4422b33cc9ebf8f980cef431e5c5c30edbf18af9732d339d23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
