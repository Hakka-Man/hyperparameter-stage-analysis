{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import st\n",
    "\n",
    "\n",
    "stockList = pd.read_pickle(\"datasets/tickerList.pkl\")\n",
    "industryList = pd.read_pickle(\"datasets/industryList.pkl\")\n",
    "sectorList = pd.read_pickle(\"datasets/sectorList.pkl\")\n",
    "stockToSectorIndustryDict = pd.read_pickle('datasets/stockToSectorIndustry.pkl')\n",
    "missingStock = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.arange(1,31)\n",
    "sumWeights = np.sum(weights)\n",
    "def calculateSlopeOfTicker(df,index):\n",
    "    if index < 31:\n",
    "        return 0\n",
    "    else:\n",
    "        return df.at[index, 'WMA30']/df.at[index-1, 'WMA30']\n",
    "\n",
    "def product(df,index):\n",
    "    if index < 30:\n",
    "        return 0\n",
    "    else:\n",
    "        return df.at[index,'Close']/df.at[index-30, 'Close']\n",
    "def calculateRS(df,dfCompare,index):\n",
    "    return df.at[index,'Percent'] - dfCompare.at[index, 'Percent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(path, comparePath = \"\", stock =''):\n",
    "    try:\n",
    "        df = pd.read_feather(path)\n",
    "        if 'WMA30Slope' not in df.columns:\n",
    "            dfCompare = [] if comparePath == \"\" else pd.read_feather(comparePath)\n",
    "            if df['Close'].isnull().values.any():\n",
    "                print(path + \" close contains null\")\n",
    "            df['FiveYearHigh'] = df['Close'].rolling(window=260).max().shift(1).fillna(0)\n",
    "            df['WMA30'] = df['Close'].rolling(window=30).apply(lambda x: np.sum(weights*x)/sumWeights)\n",
    "            df['WMA30Slope'] = 0\n",
    "            df['WMA30Slope'] = df.swifter.apply(lambda x: calculateSlopeOfTicker(df,(x.name)),axis=1)\n",
    "            df['Volume'] = df['Volume'].replace(to_replace=0, method='ffill')\n",
    "            df['Percent'] = 0\n",
    "            df['Percent'] = df.swifter.apply(lambda x: product(df,(x.name)),axis=1)\n",
    "            df = df.iloc[260:].reset_index()\n",
    "            if comparePath != \"\":\n",
    "                df['RS'] = df.swifter.apply(lambda x: calculateRS(df, dfCompare,(x.name)),axis=1)\n",
    "            df.to_feather(path)\n",
    "    except:\n",
    "        if stock != '':\n",
    "            missingStock.append(stock)\n",
    "        print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getData(\"datasets/GSPC.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sector in sectorList:\n",
    "    getData(\"datasets/sectorData/\"+sector+\".feather\", \"datasets/GSPC.feather\")\n",
    "for industry in industryList:\n",
    "    getData(\"datasets/industriesData/\"+industry[0]+\"/\"+industry[1]+\".feather\", \"datasets/sectorData/\"+sector+\".feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock in stockList[]:\n",
    "    if stock not in stockToSectorIndustryDict.keys():\n",
    "        missingStock.append(stock)\n",
    "        continue\n",
    "    getData(\"datasets/stockData/\"+stock+\".feather\",\"datasets/industriesData/\"+stockToSectorIndustryDict[stock][0]+\"/\"+stockToSectorIndustryDict[stock][1]+\".feather\",stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/missingStock.pkl', 'wb') as handle:\n",
    "    pickle.dump(missingStock, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "missingStock = pd.read_pickle('datasets/missingStock.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock in missingStock:\n",
    "    stockList.remove(stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/tickerList.pkl', 'wb') as handle:\n",
    "    pickle.dump(stockList, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('bob')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21b7bd1e2962aa9fdfcf38f5a68e339eb001c977a90403c917368d2e55c759d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
